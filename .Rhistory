rm(fileUrl_1)
}
if (!file.exists("EHII-UPDATED-10-30-2013.xlsx")) {
fileUrl_2 <- "http://utip.gov.utexas.edu/data/EHII-UPDATED-10-30-2013.xlsx"
download.file(fileUrl_2, destfile = "./EHII-UPDATED-10-30-2013.xlsx",
method = "curl")
rm(fileUrl_2)
}
if (!file.exists("SWIIDv5_0.zip")) {
fileUrl_3 <- "https://dataverse.harvard.edu/api/access/datafile/2503756"
download.file(fileUrl_3, destfile = "./SWIIDv5_0.zip", method = "curl") # 11.1mb
rm(fileUrl_3)
}
# Read the downloaded data into R
WIID <- data.table(read.xls("WIID3b_1.xls", sheet = "Sheet1")) # 4mb
EHII <- data.table(read.xlsx2("EHII-UPDATED-10-30-2013.xlsx",
sheetName = "Sheet1")) # 70kb
unzip("SWIIDv5_0.zip", unzip = "internal")
setwd("./SWIIDv5_0")
SWIID <- data.table(read_dta("SWIIDv5_0.dta"))
# Clean the WIID data
library(dplyr)
WIID <- select(WIID, Countrycode2, Countrycode3, Country, Year, Gini, Quality)
WIID$Quality <- as.character(WIID$Quality)
WIID <- filter(WIID,  Year >= 1963 & Year <= 2008)
dropped_countries <- c("Ussr", "Puerto Rico", "Taiwan", "West Bank And Gaza", "East Timor", "Yugoslavia")
WIID <- filter(WIID,  !(Country %in% dropped_countries))
WIID$Quality[WIID$Quality == "High"] <- 3
WIID$Quality[WIID$Quality == "Average"] <- 2
WIID$Quality[WIID$Quality == "Low"] <- 1
WIID$Quality[WIID$Quality == "Not known"] <- 0
aggregate(x = WIID$Quality, by = list(WIID$Country, WIID$Year), FUN = "max")
WIID$Quality[WIID$Quality == "High"] <- as.numeric(3)
WIID$Quality[WIID$Quality == "Average"] <- as.numeric(2)
WIID$Quality[WIID$Quality == "Low"] <- as.numeric(1)
WIID$Quality[WIID$Quality == "Not known"] <- as.numeric(0)
aggregate(x = WIID$Quality, by = list(WIID$Country, WIID$Year), FUN = "max")
class(WIID$Quality)
WIID$Quality[WIID$Quality == "High"] <- as.numeric(3)
WIID$Quality[WIID$Quality == "Average"] <- as.numeric(2)
WIID$Quality[WIID$Quality == "Low"] <- as.numeric(1)
WIID$Quality[WIID$Quality == "Not known"] <- as.numeric(0)
class(WIID$Quality)
WIID$Quality <- as.numeric(WIID$Quality)
aggregate(x = WIID$Quality, by = list(WIID$Country, WIID$Year), FUN = "max")
WIID$max <- aggregate(x = WIID$Quality, by = list(WIID$Country, WIID$Year), FUN = "max")
View(WIID)
max <- aggregate(x = WIID$Quality, by = list(WIID$Country, WIID$Year), FUN = "max")
View(max)
combined <- merge(WIID, max, by = intersect(names(WIID$Country), names(WIID$Year)))
combined <- merge(WIID, max, by = WIID$Country ~ WIID$Year)
combined <- merge(WIID, max, by = WIID$Country + WIID$Year)
max$x <- apply(data[ , cols ] , 1 , paste , collapse = "-" )
cols <- c('Group.1', 'Group.1')
max$x <- apply(data[ , cols ] , 1 , paste , collapse = "-" )
max$x <- apply(data[, cols ], 1 , paste , collapse = "-")
cols <- c('Group.1', 'Group.1')
max$x <- apply(data[, cols ], 1 , paste , collapse = "-")
cols <- c('Group.1', 'Group.2')
max$x <- apply(data[, cols ], 1 , paste , collapse = "-")
cols <- c('Group.1', 'Group.2')
max$x <- do.call(paste, c(max[cols], sep="-"))
View(max)
max <- aggregate(x = WIID$Quality, by = list(WIID$Country, WIID$Year), FUN = "max"
max <- aggregate(x = WIID$Quality, by = list(WIID$Country, WIID$Year), FUN = "max")
View(max)
cols <- c('Group.1', 'Group.2')
max$x <- do.call(paste, c(max[cols], sep="-"))
View(max)
max <- aggregate(x = WIID$Quality, by = list(WIID$Country, WIID$Year), FUN = "max")
cols <- c('Group.1', 'Group.2')
max$ID <- do.call(paste, c(max[cols], sep="-"))
View(max)
View(WIID)
WIID$Quality[WIID$Quality == "High"]
WIID$Quality[WIID$Quality == "Average"]
WIID$Quality[WIID$Quality == "Low"]
WIID$Quality[WIID$Quality == "Not known"]
WIID$Quality <- as.numeric(WIID$Quality)
cols <- c('Country', 'Year')                                                            # create an ID variable
WIID$ID <- do.call(paste, c(WIID[cols], sep="-"))                                       # create an ID variable
max <- aggregate(x = WIID$Quality, by = list(WIID$Country, WIID$Year), FUN = "max")     # create a max value
cols <- c('Group.1', 'Group.2')                                                         # create an ID variable
max$ID <- do.call(paste, c(max[cols], sep="-"))                                         # create an ID variable
cols1 <- c('Country', 'Year')                                                            # create an ID variable
WIID$ID <- do.call(paste, c(WIID[cols1], sep="-"))
cols1
WIID$ID <- do.call(paste, c(WIID[,cols1], sep="-"))
cols2 <- c('Group.1', 'Group.2')                                                         # create an ID variable
max$ID <- do.call(paste, c(max[cols2]))
View(max)
cols1 <- c('Country', 'Year')                                                            # create an ID variable
WIID$ID <- do.call(paste, c(WIID[cols1], sep=""))
?setkey
setkey(SWIID)
cols1 <- c('Country', 'Year')                                                            # create an ID variable
WIID$ID <- do.call(paste, c(WIID[cols1], sep=""))
setkey(SWIID, Countrycode2)
cols1 <- c('Country', 'Year')                                                            # create an ID variable
WIID$ID <- do.call(paste, c(WIID[cols1], sep=""))
################################################################################
## File name: 	Reexamining_Heckscher-Ohlin.R
## Date: 		    August 29, 2015
## Author: 		  Benjamin S. Knight (knight.benjamin@gmail.com)
## Purpose: 	  Downloads and creates data tables of economic inequality from
##              three major datasets: The Standardized World Income Inequality
##              Database (SWIID) by Frederick Solt, the Estimated Household
##              Income Inequality Data Set by the University of Texas Inequality
##              Project, and the UNU-WIDER World Income Inequality Database
##              (WIID) from the United Nations University World Institute for
##              Development Economics Research
################################################################################
# clear working environment
rm(list=ls())
# install necessary packages
# install.packages("xlsx")
# install.packages("gdata")
# install.packages("data.table")
devtools::install_github("hadley/haven")
require(haven)
# NOTE: You may need to update Java from
# https://support.apple.com/kb/DL1572?locale=en_US to run the xlsx package
require(xlsx)
library(gdata)
library(readstata13)
library(data.table)
setwd(paste("/Users/benjaminknight/Documents",
"/Personal Training/Trade Project",
"/GitVersion", sep=""))
if (!file.exists("data")) {dir.create("data")}
setwd("./data")
if (!file.exists("WIID3b_1.xls")) {
fileUrl_1 <- paste("http://www.wider.unu.edu/research/WIID3-0B",
"/en_GB/wiid/_files/92393927664936620",
"/default/WIID3b.xls", sep="")
download.file(fileUrl_1, destfile = "./WIID3b_1.xls")
rm(fileUrl_1)
}
if (!file.exists("EHII-UPDATED-10-30-2013.xlsx")) {
fileUrl_2 <- "http://utip.gov.utexas.edu/data/EHII-UPDATED-10-30-2013.xlsx"
download.file(fileUrl_2, destfile = "./EHII-UPDATED-10-30-2013.xlsx",
method = "curl")
rm(fileUrl_2)
}
if (!file.exists("SWIIDv5_0.zip")) {
fileUrl_3 <- "https://dataverse.harvard.edu/api/access/datafile/2503756"
download.file(fileUrl_3, destfile = "./SWIIDv5_0.zip", method = "curl") # 11.1mb
rm(fileUrl_3)
}
# Read the downloaded data into R
WIID <- data.table(read.xls("WIID3b_1.xls", sheet = "Sheet1")) # 4mb
EHII <- data.table(read.xlsx2("EHII-UPDATED-10-30-2013.xlsx",
sheetName = "Sheet1")) # 70kb
unzip("SWIIDv5_0.zip", unzip = "internal")
setwd("./SWIIDv5_0")
SWIID <- data.table(read_dta("SWIIDv5_0.dta"))
# Clean the WIID data
library(dplyr)
WIID <- select(WIID, Countrycode2, Countrycode3, Country, Year, Gini, Quality)
WIID$Quality <- as.character(WIID$Quality)
WIID <- filter(WIID,  Year >= 1963 & Year <= 2008)
dropped_countries <- c("Ussr", "Puerto Rico", "Taiwan", "West Bank And Gaza", "East Timor", "Yugoslavia")
WIID <- filter(WIID,  !(Country %in% dropped_countries))
WIID$Quality[WIID$Quality == "High"]
WIID$Quality[WIID$Quality == "Average"]
WIID$Quality[WIID$Quality == "Low"]
WIID$Quality[WIID$Quality == "Not known"]
WIID$Quality <- as.numeric(WIID$Quality)
View(WIID)
WIID <- data.table(read.xls("WIID3b_1.xls", sheet = "Sheet1")) # 4mb
library(dplyr)
WIID <- select(WIID, Countrycode2, Countrycode3, Country, Year, Gini, Quality)
WIID$Quality <- as.character(WIID$Quality)
WIID <- filter(WIID,  Year >= 1963 & Year <= 2008)
dropped_countries <- c("Ussr", "Puerto Rico", "Taiwan", "West Bank And Gaza", "East Timor", "Yugoslavia")
WIID <- filter(WIID,  !(Country %in% dropped_countries))
WIID$Quality[WIID$Quality == "High"] <- 3
WIID$Quality[WIID$Quality == "Average"] <- 2
WIID$Quality[WIID$Quality == "Low"] <- 1
WIID$Quality[WIID$Quality == "Not known"] <- 0
WIID$Quality <- as.numeric(WIID$Quality)
cols1 <- c('Country', 'Year')                                                            # create an ID variable
WIID$ID <- do.call(paste, c(WIID[cols1], sep=""))
WIID$ID = WIID$Country . WIID$Year;
WIID$ID = WIID$Country + WIID$Year;
WIID$ID <- WIID$Country . WIID$Year;
WIID$ID <- WIID$Country + WIID$Year
WIID$ID <- as.string(WIID$Country) + as.string(WIID$Year)
WIID$ID <- as.character(WIID$Country) + as.character(WIID$Year)
WIID$ID <- toString(WIID$Country) + toString(WIID$Year)
WIID$ID <- c(toString(WIID$Country), toString(WIID$Year))
View(WIID)
WIID$ID <- c(WIID$Country, WIID$Year)
View(WIID)
WIID$ID <- c(as.character(WIID$Country), as.character(WIID$Year))
View(WIID)
WIID$ID <- do.call(paste, (WIID$Country), as.character(WIID$Year))
WIID$ID <- do.call(paste, c(WIID$Country, WIID$Year))
WIID$ID <- as.character(paste(WIID$Country, WIID$Year, sep = ""))
View(WIID)
################################################################################
## File name: 	Reexamining_Heckscher-Ohlin.R
## Date: 		    August 29, 2015
## Author: 		  Benjamin S. Knight (knight.benjamin@gmail.com)
## Purpose: 	  Downloads and creates data tables of economic inequality from
##              three major datasets: The Standardized World Income Inequality
##              Database (SWIID) by Frederick Solt, the Estimated Household
##              Income Inequality Data Set by the University of Texas Inequality
##              Project, and the UNU-WIDER World Income Inequality Database
##              (WIID) from the United Nations University World Institute for
##              Development Economics Research
################################################################################
# clear working environment
rm(list=ls())
# install necessary packages
# install.packages("xlsx")
# install.packages("gdata")
# install.packages("data.table")
devtools::install_github("hadley/haven")
require(haven)
# NOTE: You may need to update Java from
# https://support.apple.com/kb/DL1572?locale=en_US to run the xlsx package
require(xlsx)
library(gdata)
library(readstata13)
library(data.table)
setwd(paste("/Users/benjaminknight/Documents",
"/Personal Training/Trade Project",
"/GitVersion", sep=""))
if (!file.exists("data")) {dir.create("data")}
setwd("./data")
if (!file.exists("WIID3b_1.xls")) {
fileUrl_1 <- paste("http://www.wider.unu.edu/research/WIID3-0B",
"/en_GB/wiid/_files/92393927664936620",
"/default/WIID3b.xls", sep="")
download.file(fileUrl_1, destfile = "./WIID3b_1.xls")
rm(fileUrl_1)
}
if (!file.exists("EHII-UPDATED-10-30-2013.xlsx")) {
fileUrl_2 <- "http://utip.gov.utexas.edu/data/EHII-UPDATED-10-30-2013.xlsx"
download.file(fileUrl_2, destfile = "./EHII-UPDATED-10-30-2013.xlsx",
method = "curl")
rm(fileUrl_2)
}
if (!file.exists("SWIIDv5_0.zip")) {
fileUrl_3 <- "https://dataverse.harvard.edu/api/access/datafile/2503756"
download.file(fileUrl_3, destfile = "./SWIIDv5_0.zip", method = "curl") # 11.1mb
rm(fileUrl_3)
}
# Read the downloaded data into R
WIID <- data.table(read.xls("WIID3b_1.xls", sheet = "Sheet1")) # 4mb
EHII <- data.table(read.xlsx2("EHII-UPDATED-10-30-2013.xlsx",
sheetName = "Sheet1")) # 70kb
unzip("SWIIDv5_0.zip", unzip = "internal")
setwd("./SWIIDv5_0")
SWIID <- data.table(read_dta("SWIIDv5_0.dta"))
# Clean the WIID data
library(dplyr)
WIID <- select(WIID, Countrycode2, Countrycode3, Country, Year, Gini, Quality)
WIID$Quality <- as.character(WIID$Quality)
WIID <- filter(WIID,  Year >= 1963 & Year <= 2008)
dropped_countries <- c("Ussr", "Puerto Rico", "Taiwan", "West Bank And Gaza", "East Timor", "Yugoslavia")
WIID <- filter(WIID,  !(Country %in% dropped_countries))
WIID$Quality[WIID$Quality == "High"] <- 3
WIID$Quality[WIID$Quality == "Average"] <- 2
WIID$Quality[WIID$Quality == "Low"] <- 1
WIID$Quality[WIID$Quality == "Not known"] <- 0
WIID$Quality <- as.numeric(WIID$Quality)
WIID$ID <- as.character(paste(WIID$Country, WIID$Year, sep = ""))                        # create an ID variable
max <- aggregate(x = WIID$Quality, by = list(WIID$Country, WIID$Year), FUN = "max")      # create a max value
max$ID <- as.character(paste(WIID$Group.1, WIID$Group.1, sep = ""))                      # create an ID variable                                  # create an ID variable
View(WIID)
View(WIID)
View(max)
max$ID <- as.character(paste(max$Group.1, max$Group.1, sep = ""))                        # create an ID variable
View(max)
combined <- merge(WIID, max, by = ID)
View(WIID)
View(max)
combined <- merge(WIID, max, ID)
combined <- merge(WIID, max, by = "ID")
View(combined)
View(WIID)
max$ID <- as.character(paste(max$Group.1, max$Group.2, sep = ""))
combined <- merge(WIID, max, by = "ID")
View(combined)
WIID$ID <- as.character(paste(WIID$Country, WIID$Year, sep = ""))                        # create an ID variable
max <- aggregate(max = WIID$Quality, by = list(WIID$Country, WIID$Year), FUN = "max")    # create a max value
max$ID <- as.character(paste(max$Group.1, max$Group.2, sep = ""))                        # create an ID variable
combined <- merge(WIID, max, by = "ID")                                                  # merge data sets
combined <- merge(WIID, max, by = "ID")                                                  # merge data sets
myvars <- c("Countrycode1", "Countrycode2", "Country", "Year", "Gini", "Quality")
combined <- combined[myvars]
myvars <- c("Country", "Year", "Gini", "Quality")
combined <- combined[myvars]
newdata <- combined[c("Country", "Year", "Gini", "Quality")]
View(combined)
library(dplyr)
WIID <- select(WIID, Countrycode2, Countrycode3, Country, Year, Gini, Quality)
WIID$Quality <- as.character(WIID$Quality)
WIID <- filter(WIID,  Year >= 1963 & Year <= 2008)
dropped_countries <- c("Ussr", "Puerto Rico", "Taiwan", "West Bank And Gaza", "East Timor", "Yugoslavia")
WIID <- filter(WIID,  !(Country %in% dropped_countries))
WIID$Quality[WIID$Quality == "High"] <- 3
WIID$Quality[WIID$Quality == "Average"] <- 2
WIID$Quality[WIID$Quality == "Low"] <- 1
WIID$Quality[WIID$Quality == "Not known"] <- 0
WIID$Quality <- as.numeric(WIID$Quality)
WIID$ID <- as.character(paste(WIID$Country, WIID$Year, sep = ""))                        # create an ID variable
max <- aggregate(x = WIID$Quality, by = list(WIID$Country, WIID$Year), FUN = "max")      # create a max value
max$ID <- as.character(paste(max$Group.1, max$Group.2, sep = ""))                        # create an ID variable
combined <- merge(WIID, max, by = "ID")                                                  # merge data sets
newdata <- combined[c("Country", "Year", "Gini", "Quality")]
View(newdata)
newdata <- mydata[c(2:7,10)]
newdata <- combined[c(2:7,1
newdata <- combined[c(2:7,10)]
View(newdata)
View(combined)
combined <- select(combined, Countrycode2, Countrycode3, Country, Year, Gini, Quality, x)
View(combined)
combined <- combined[combined$Quality >= combined$x]
View(combined)
combined$Gini <- aggregate(x = WIID$Gini, by = list(combined$Country, combined$Year), FUN = "mean"
combined$Gini <- aggregate(x = WIID$Gini, by = list(combined$Country, combined$Year), FUN = "mean")
combined$Z <- aggregate(x = WIID$Gini, by = list(combined$Country, combined$Year), FUN = "mean")
means <- aggregate(x = WIID$Gini, by = list(combined$Country, combined$Year), FUN = "mean")
install.packages("doBy")
library(doBy)
x <- summaryBy(Gini ~ Country + Year, data=combined)
View(x)
SWIID <- dcast(combined, Country ~ Year, value.var = "Gini")
library(reshape2)
z <- dcast(combined, Country ~ Year, value.var = "Gini")
View(z)
combined <- summaryBy(Gini ~ Country + Year, data = combined)
View(combined)
z <- dcast(combined, Country ~ Year, value.var = "Gini.mean")
View(z)
WIID <- dcast(combined, Country ~ Year, value.var = "Gini.mean")
View(WIID)
################################################################################
## File name: 	Reexamining_Heckscher-Ohlin.R
## Date: 		    August 29, 2015
## Author: 		  Benjamin S. Knight (knight.benjamin@gmail.com)
## Purpose: 	  Downloads and creates data tables of economic inequality from
##              three major datasets: The Standardized World Income Inequality
##              Database (SWIID) by Frederick Solt, the Estimated Household
##              Income Inequality Data Set by the University of Texas Inequality
##              Project, and the UNU-WIDER World Income Inequality Database
##              (WIID) from the United Nations University World Institute for
##              Development Economics Research
################################################################################
# clear working environment
rm(list=ls())
# install necessary packages
# install.packages("xlsx")
# install.packages("gdata")
# install.packages("data.table")
devtools::install_github("hadley/haven")
require(haven)
# NOTE: You may need to update Java from
# https://support.apple.com/kb/DL1572?locale=en_US to run the xlsx package
require(xlsx)
library(gdata)
library(readstata13)
library(data.table)
setwd(paste("/Users/benjaminknight/Documents",
"/Personal Training/Trade Project",
"/GitVersion", sep=""))
if (!file.exists("data")) {dir.create("data")}
setwd("./data")
if (!file.exists("WIID3b_1.xls")) {
fileUrl_1 <- paste("http://www.wider.unu.edu/research/WIID3-0B",
"/en_GB/wiid/_files/92393927664936620",
"/default/WIID3b.xls", sep="")
download.file(fileUrl_1, destfile = "./WIID3b_1.xls")
rm(fileUrl_1)
}
if (!file.exists("EHII-UPDATED-10-30-2013.xlsx")) {
fileUrl_2 <- "http://utip.gov.utexas.edu/data/EHII-UPDATED-10-30-2013.xlsx"
download.file(fileUrl_2, destfile = "./EHII-UPDATED-10-30-2013.xlsx",
method = "curl")
rm(fileUrl_2)
}
if (!file.exists("SWIIDv5_0.zip")) {
fileUrl_3 <- "https://dataverse.harvard.edu/api/access/datafile/2503756"
download.file(fileUrl_3, destfile = "./SWIIDv5_0.zip", method = "curl") # 11.1mb
rm(fileUrl_3)
}
# Read the downloaded data into R
WIID <- data.table(read.xls("WIID3b_1.xls", sheet = "Sheet1")) # 4mb
EHII <- data.table(read.xlsx2("EHII-UPDATED-10-30-2013.xlsx",
sheetName = "Sheet1")) # 70kb
unzip("SWIIDv5_0.zip", unzip = "internal")
setwd("./SWIIDv5_0")
SWIID <- data.table(read_dta("SWIIDv5_0.dta"))
# Clean the WIID data
library(dplyr)
WIID <- select(WIID, Countrycode2, Countrycode3, Country, Year, Gini, Quality)
WIID$Quality <- as.character(WIID$Quality)
WIID <- filter(WIID,  Year >= 1963 & Year <= 2008)
dropped_countries <- c("Ussr", "Puerto Rico", "Taiwan", "West Bank And Gaza", "East Timor", "Yugoslavia")
WIID <- filter(WIID,  !(Country %in% dropped_countries))
WIID$Quality[WIID$Quality == "High"] <- 3
WIID$Quality[WIID$Quality == "Average"] <- 2
WIID$Quality[WIID$Quality == "Low"] <- 1
WIID$Quality[WIID$Quality == "Not known"] <- 0
WIID$Quality <- as.numeric(WIID$Quality)
WIID$ID <- as.character(paste(WIID$Country, WIID$Year, sep = ""))                        # create an ID variable
max <- aggregate(x = WIID$Quality, by = list(WIID$Country, WIID$Year), FUN = "max")      # create a max value
max$ID <- as.character(paste(max$Group.1, max$Group.2, sep = ""))                        # create an ID variable
combined <- merge(WIID, max, by = "ID")                                                  # merge data sets
combined <- select(combined, Countrycode2, Countrycode3, Country, Year, Gini, Quality, x)
combined <- combined[combined$Quality >= combined$x]
library(doBy)
combined <- summaryBy(Gini ~ Country + Year, data = combined)
library(reshape2)
WIID <- dcast(combined, Country ~ Year, value.var = "Gini.mean")
rm(max, newdata, combined, dropped_countries)
################################################################################
## File name: 	Reexamining_Heckscher-Ohlin.R
## Date: 		    August 29, 2015
## Author: 		  Benjamin S. Knight (knight.benjamin@gmail.com)
## Purpose: 	  Downloads and creates data tables of economic inequality from
##              three major datasets: The Standardized World Income Inequality
##              Database (SWIID) by Frederick Solt, the Estimated Household
##              Income Inequality Data Set by the University of Texas Inequality
##              Project, and the UNU-WIDER World Income Inequality Database
##              (WIID) from the United Nations University World Institute for
##              Development Economics Research
################################################################################
# clear working environment
rm(list=ls())
# install necessary packages
# install.packages("xlsx")
# install.packages("gdata")
# install.packages("data.table")
devtools::install_github("hadley/haven")
require(haven)
# NOTE: You may need to update Java from
# https://support.apple.com/kb/DL1572?locale=en_US to run the xlsx package
require(xlsx)
library(gdata)
library(readstata13)
library(data.table)
setwd(paste("/Users/benjaminknight/Documents",
"/Personal Training/Trade Project",
"/GitVersion", sep=""))
if (!file.exists("data")) {dir.create("data")}
setwd("./data")
if (!file.exists("WIID3b_1.xls")) {
fileUrl_1 <- paste("http://www.wider.unu.edu/research/WIID3-0B",
"/en_GB/wiid/_files/92393927664936620",
"/default/WIID3b.xls", sep="")
download.file(fileUrl_1, destfile = "./WIID3b_1.xls")
rm(fileUrl_1)
}
if (!file.exists("EHII-UPDATED-10-30-2013.xlsx")) {
fileUrl_2 <- "http://utip.gov.utexas.edu/data/EHII-UPDATED-10-30-2013.xlsx"
download.file(fileUrl_2, destfile = "./EHII-UPDATED-10-30-2013.xlsx",
method = "curl")
rm(fileUrl_2)
}
if (!file.exists("SWIIDv5_0.zip")) {
fileUrl_3 <- "https://dataverse.harvard.edu/api/access/datafile/2503756"
download.file(fileUrl_3, destfile = "./SWIIDv5_0.zip", method = "curl") # 11.1mb
rm(fileUrl_3)
}
# Read the downloaded data into R
WIID <- data.table(read.xls("WIID3b_1.xls", sheet = "Sheet1")) # 4mb
EHII <- data.table(read.xlsx2("EHII-UPDATED-10-30-2013.xlsx",
sheetName = "Sheet1")) # 70kb
unzip("SWIIDv5_0.zip", unzip = "internal")
setwd("./SWIIDv5_0")
SWIID <- data.table(read_dta("SWIIDv5_0.dta"))
# Clean the WIID data
library(dplyr)
WIID <- select(WIID, Countrycode2, Countrycode3, Country, Year, Gini, Quality)
WIID$Quality <- as.character(WIID$Quality)
WIID <- filter(WIID,  Year >= 1963 & Year <= 2008)
dropped_countries <- c("Ussr", "Puerto Rico", "Taiwan", "West Bank And Gaza", "East Timor", "Yugoslavia")
WIID <- filter(WIID,  !(Country %in% dropped_countries))
WIID$Quality[WIID$Quality == "High"] <- 3
WIID$Quality[WIID$Quality == "Average"] <- 2
WIID$Quality[WIID$Quality == "Low"] <- 1
WIID$Quality[WIID$Quality == "Not known"] <- 0
WIID$Quality <- as.numeric(WIID$Quality)
WIID$ID <- as.character(paste(WIID$Country, WIID$Year, sep = ""))                        # create an ID variable
max <- aggregate(x = WIID$Quality, by = list(WIID$Country, WIID$Year), FUN = "max")      # create a max value
max$ID <- as.character(paste(max$Group.1, max$Group.2, sep = ""))                        # create an ID variable
combined <- merge(WIID, max, by = "ID")                                                  # merge data sets
combined <- select(combined, Countrycode2, Countrycode3, Country, Year, Gini, Quality, x)
combined <- combined[combined$Quality >= combined$x]
library(doBy)
combined <- summaryBy(Gini ~ Country + Year, data = combined)
library(reshape2)
WIID <- dcast(combined, Country ~ Year, value.var = "Gini.mean")
rm(max, combined, dropped_countries)
View(WIID)
rm(list=ls())
setwd(paste("/Users/benjaminknight/Documents",
"/Personal Training/Trade Project/GitVersion", sep=""))
# install.packages("knitr")
library(knitr)
knit2html("HO.Rmd")
rm(list=ls())
setwd(paste("/Users/benjaminknight/Documents",
"/Personal Training/Trade Project/GitVersion", sep=""))
# install.packages("knitr")
library(knitr)
knit2html("HO.Rmd")
